{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])#for train\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [transforms.Resize((256, 256)),\n",
    "     transforms.CenterCrop((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])# for eval/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.ImageFolder('../input/caltech101/Caltech101/Caltech101/train',transform=transform1)\n",
    "eval_data=torchvision.datasets.ImageFolder('../input/caltech101/Caltech101/Caltech101/eval',transform=transform2)\n",
    "test_data=torchvision.datasets.ImageFolder('../input/caltech101/Caltech101/Caltech101/test',transform=transform2)\n",
    "\n",
    "train_loader=Data.DataLoader(dataset=train_data,batch_size=16,\n",
    "                             shuffle=True, num_workers=2)\n",
    "eval_loader=Data.DataLoader(dataset=eval_data,batch_size=128,\n",
    "                             shuffle=True, num_workers=2)\n",
    "test_loader=Data.DataLoader(dataset=test_data,batch_size=128,\n",
    "                             shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):#for resnet 18 (only has 2 3*3,64)\n",
    "    expansion = 1 # whether the number of kernels changed\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):#downsample is for the dotted line in the image\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "                                                                    #stride=1 means the solid line in the image output=input\n",
    "                                                                    #while 2 menas the dotted line output=input/2\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)#bias=false because batch normalization\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)#mind no relu\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):# for resnet 50\n",
    "    expansion = 4# because the latter one is four times of the previous\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=1, stride=1, bias=False)  # squeeze channels; #no changing size\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "      \n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x #output of the shortcut\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)# mind no relu\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, blocks_num, num_classes=1000, include_top=True):#block=BasicBlock/bottleneck\n",
    "        #include_top is for other improvement(more complex network) based on resnet\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)#7*7,64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():#initialize conv layer\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:#this works only for resnet 50and more\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel, channel))# add the central part(solid line part)\n",
    "\n",
    "        return nn.Sequential(*layers)#key word\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(num_classes=1000, include_top=True):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnet50(num_classes=1000, include_top=True):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn = resnet50(num_classes=101).cuda()\n",
    "#rnn = resnet50()\n",
    "rnn = resnet18()\n",
    "#print(rnn)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_path = \"../input/pretrained-pytorch-models/resnet18-5c106cde.pth\"\n",
    "#model_weight_path = \"../input/pretrained-pytorch-models/resnet50-19c8e357.pth\"\n",
    "missing_keys, unexpected_keys = rnn.load_state_dict(torch.load(model_weight_path), strict=False)\n",
    "# for param in net.parameters():\n",
    "#     param.requires_grad = False\n",
    "# change fc layer structure\n",
    "inchannel = rnn.fc.in_features\n",
    "rnn.fc = nn.Linear(inchannel, 101)\n",
    "rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 40\n",
    "\n",
    "LR=0.001\n",
    "stepsize=40\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "optimizer=torch.optim.Adam(rnn.parameters(),lr=LR,weight_decay=1e-5)\n",
    "loss_func=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=40\n",
    "best_acc = 0.0\n",
    "train_num = len(train_data)\n",
    "val_num = len(eval_data)\n",
    "losses=[]\n",
    "eval_accs=[]\n",
    "train_accs=[]\n",
    "for epoch in range(EPOCH):\n",
    "    # train\n",
    "    rnn.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc=[]\n",
    "    acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = rnn(images.cuda())\n",
    "        loss = loss_func(logits, labels.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predict_y = torch.max(logits, dim=1)[1]\n",
    "        acc += (predict_y == labels.cuda()).sum().item()\n",
    "        train_accurate = acc / train_num\n",
    "        train_acc.append(train_accurate)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print train process\n",
    "        rate = (step+1)/len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.4f}\".format(int(rate*100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accs.append(train_acc[-1])\n",
    "\n",
    "    # validate\n",
    "    torch.cuda.empty_cache()\n",
    "    rnn.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        for val_data in eval_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = rnn(val_images.cuda())  # eval model only have last output layer\n",
    "            # loss = loss_function(outputs, test_labels)\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += (predict_y == val_labels.cuda()).sum().item()\n",
    "        val_accurate = acc / val_num\n",
    "        eval_accs.append(val_accurate)\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            \n",
    "        print('[epoch %d] train_loss: %.3f  test_accuracy: %.3f train_accuracy: %.3f   ' %\n",
    "              (epoch + 1, running_loss / step, val_accurate,train_accs[-1]))\n",
    "        losses.append(running_loss / step)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(losses))\n",
    "plt.plot(x,losses)\n",
    "#plt.plot(x,eval_losses)\n",
    "plt.title('resnet 50 transfer Loss ')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(train_accs))\n",
    "\n",
    "plt.plot(x,train_accs,label='train')\n",
    "plt.plot(x,eval_accs,label='validate')\n",
    "plt.title('resnet 50 transfer Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
